{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy much of the procedures from previous explorations, but this time focus on using scikit-learn models and finding the best one.\n",
    "\n",
    "Repository for this code: https://github.com/TheCDC/CSC413_Midterm_Project\n",
    "\n",
    "Choosing a model: http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "List of linear models: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model\n",
    "\n",
    "\n",
    "Reference: https://www.cs.ucsb.edu/%7Ewilliam/papers/acl2017.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar imports as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10241"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_text_mapping = {\n",
    "    'pants-fire': 0,\n",
    "    'false': 1,\n",
    "    'barely-true': 2,\n",
    "    'half-true': 3,\n",
    "    'mostly-true': 4,\n",
    "    'true': 5,\n",
    "}\n",
    "\n",
    "\n",
    "class Statement:\n",
    "    def __init__(self, body, speaker, value, context):\n",
    "        self.body = body\n",
    "        self.speaker = speaker\n",
    "        self.value = truth_text_mapping[value]\n",
    "        self.context = context\n",
    "\n",
    "    @staticmethod\n",
    "    def from_row(row):\n",
    "        return Statement(value=row[1],\n",
    "                         body=row[2],\n",
    "                         speaker=row[4],\n",
    "                         context=row[13])\n",
    "\n",
    "    def __repr__(self):\n",
    "        arg_str = str(', '.join(['='.join([i[0], repr(i[1])])\n",
    "                                 for i in vars(self).items()]))\n",
    "        return \"Statement({})\".format(arg_str)\n",
    "\n",
    "    def __str__(self):\n",
    "        return repr(self)\n",
    "\n",
    "    @property\n",
    "    def features(self):\n",
    "        return ' '.join([self.speaker, self.context, self.body])\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def load_liar_data(path):\n",
    "    statements = []\n",
    "    with open(path) as data_file:\n",
    "        reader = csv.reader(data_file, delimiter='\\t', quotechar='\"')\n",
    "        for row in reader:\n",
    "            try:\n",
    "                statements.append(Statement.from_row(row))\n",
    "            except IndexError:\n",
    "                print(row, len(row))\n",
    "    return statements\n",
    "\n",
    "\n",
    "statements = load_liar_data(\"../datasets/LIAR/train.tsv\")\n",
    "# print out some statements to verify by eye.\n",
    "len(statements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize the training data via sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: (10241, 14552)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<10241x14552 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 221431 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x = vectorizer.fit_transform([s.features for s in statements])\n",
    "y = np.array([s.value for s in statements]).ravel()\n",
    "\n",
    "# vocab\n",
    "# statements[0].body\n",
    "print('Vocab size:', x.shape)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the regression model against the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73765150487092312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.Ridge(fit_intercept=True, alpha=0.01)\n",
    "clf.fit(x, y)\n",
    "clf.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bad score on the training data is not promising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.18428915852079597"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_statements = load_liar_data(\"../datasets/LIAR/test.tsv\")\n",
    "x_test = vectorizer.transform([s.features for s in test_statements])\n",
    "y_test = np.array([s.value for s in test_statements]).ravel()\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.6981627780554429, 5),\n",
       " (2.3943054810660889, 1),\n",
       " (1.4846024236565638, 1),\n",
       " (1.5923527449103883, 3),\n",
       " (0.61512542788298097, 0),\n",
       " (3.1396738979990655, 5),\n",
       " (3.7472879880233894, 5),\n",
       " (0.35950924016343855, 2),\n",
       " (2.6628539526986645, 5),\n",
       " (4.4398964812644159, 2),\n",
       " (2.6073627088634286, 2),\n",
       " (0.0023495192461071568, 2),\n",
       " (0.19147823712872247, 0),\n",
       " (1.5131455488610017, 1),\n",
       " (2.0087359387436363, 3),\n",
       " (2.5033620682511883, 5),\n",
       " (1.8920736856669986, 0),\n",
       " (2.5360836997720897, 3),\n",
       " (2.9556110125594217, 5),\n",
       " (2.469653323641547, 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out some predicted vs. actual values\n",
    "list(zip(clf.predict(x_test), y_test[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 -0.168200480777\n",
      "0.16681005372 -0.160992548303\n",
      "0.278255940221 -0.150582729315\n",
      "0.464158883361 -0.135034903273\n",
      "0.774263682681 -0.111858085519\n",
      "1.29154966501 -0.0813207911703\n",
      "2.15443469003 -0.0452453448098\n",
      "3.5938136638 -0.00510536231343\n",
      "5.99484250319 0.0327295465867\n",
      "10.0 0.0655838577779\n",
      "(10.0, 0.065583857777861798)\n"
     ]
    }
   ],
   "source": [
    "# find optimal alpha for linear Ridge model\n",
    "clf = linear_model.Ridge(fit_intercept=True)\n",
    "best = None\n",
    "for al in np.logspace(-1, 1, 10):\n",
    "    clf.set_params(alpha=al)\n",
    "    clf.fit(x, y)\n",
    "    s = clf.score(x_test, y_test)\n",
    "    if best is None or s > best[1]:\n",
    "        best = (al, s)\n",
    "    print(al, s)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=10.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.set_params(alpha=best[0])\n",
    "clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06545819913249773"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.7594321883696065, 5),\n",
       " (2.5446481776419683, 2),\n",
       " (1.6250822235700111, 2),\n",
       " (1.7606811898223107, 3),\n",
       " (1.0883171284360318, 4),\n",
       " (2.7344527249075918, 4),\n",
       " (3.0576007305170365, 5),\n",
       " (1.1372971751590499, 4),\n",
       " (2.4557353260277579, 1),\n",
       " (3.8825840750344978, 0),\n",
       " (2.8292044155289315, 0),\n",
       " (1.362745192491009, 3),\n",
       " (0.62440738983604582, 2),\n",
       " (2.0212172305660516, 1),\n",
       " (2.479063328146335, 0),\n",
       " (2.4937448739382062, 3),\n",
       " (1.82199953410074, 2),\n",
       " (2.1844813724470371, 2),\n",
       " (3.0034227534368925, 2),\n",
       " (2.9471367988463322, 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out some predicted vs. actual values\n",
    "list(zip(clf.predict(x_test), y_test[-20:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantify the performance of other models.\n",
    "FLowchart for choosing models found here: http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22415153906866614"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC\n",
    "clf = model()\n",
    "clf.fit(x, y)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19021310181531176"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(x.toarray(), y)\n",
    "clf.score(x_test.toarray(), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26045777426992894"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x, y)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27703235990528807"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(x, y)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012527445600031273"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.Lasso(alpha=0.1)\n",
    "clf.fit(x, y)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "The paper achieved similar accuracy to my experiments here at about 22% to 27%. It is clear that the core assumption that the truth/fake value of a statement can be inferred from the vocabulary and structure is flawed. It is possible that a model that actually understands English and manners of speech could get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
